{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de spanBERTa_haha2019.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJNPf4FFibo9W3H7lCUOEe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X8lW-xPeQW46"},"source":["https://www.kaggle.com/jaskaransingh/fake-news-classification-bert-roberta\n","https://towardsdatascience.com/text-classification-with-hugging-face-transformers-in-tensorflow-2-without-tears-ee50e4f3e7ed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msn_Sbsp2WEf","executionInfo":{"status":"ok","timestamp":1622117906154,"user_tz":-120,"elapsed":5296,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"adeedb3c-6b71-43e5-fc96-006faff8f411"},"source":["!pip install transformers"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NVboFNZyTsiD","executionInfo":{"status":"ok","timestamp":1622117906154,"user_tz":-120,"elapsed":4,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["# Libraries\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer\n","from transformers import Trainer, TrainingArguments\n","# Evaluation\n","# import pytorch\n","import torch\n","from torch import nn\n","# import tensorflow_text as text\n","import pandas as pd\n","# from official.nlp import optimization  # to create AdamW optimizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","#import np_utils\n","from keras import backend as K\n","# from focal_loss import BinaryFocalLoss\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import activations\n","# import tensorflow_addons as tfa\n","\n","\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"KgRYY8LYTxva","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622117911549,"user_tz":-120,"elapsed":5398,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"df2c4167-d7ed-463c-dc44-7eaa3b822773"},"source":["BATCH_SIZE = 32\n","PRETRAINED_MODEL_NAME = \"skimai/spanberta-base-cased\"\n","MAX_SEQUENCE_LENGTH = 125\n","bert_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","#bert_model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME,num_labels=2) #FOR CLASSIFICATION\n","bert_model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME,num_labels=1) #FOR REGRESSION"],"execution_count":21,"outputs":[{"output_type":"stream","text":["You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skimai/spanberta-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3aRPCSCI6HYQ","executionInfo":{"status":"ok","timestamp":1622117900861,"user_tz":-120,"elapsed":4337,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["# Read data\n","url = 'https://www.fing.edu.uy/inco/grupos/pln/haha/2019/data/haha_2019_train.csv'\n","url2 = 'https://www.fing.edu.uy/inco/grupos/pln/haha/2019/data/haha_2019_test_gold.csv'\n","train = pd.read_csv(url)\n","testG = pd.read_csv(url2)\n","\n","train = train.loc[train['is_humor'] == 1].copy()\n","testG = testG.loc[testG['is_humor'] == 1].copy()"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsTdxHM_4VDY","executionInfo":{"status":"ok","timestamp":1622117913535,"user_tz":-120,"elapsed":1997,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["x_train, x_dev,y_train, y_dev = train_test_split(train[\"text\"].tolist(),train[\"funniness_average\"].tolist(), test_size=0.2,stratify=train[\"is_humor\"])\n","\n","x_test = testG[\"text\"].tolist()\n","y_test = testG[\"funniness_average\"].tolist()\n","\n","\n","\n","train_encod = bert_tokenizer(x_train,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH) \n","val_encod = bert_tokenizer(x_dev,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH)\n","test_encod = bert_tokenizer(x_test,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH)\n","\n","class NewsGroupsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor([self.labels[idx]])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_ds = NewsGroupsDataset(train_encod, y_train)\n","dev_ds = NewsGroupsDataset(val_encod, y_dev)\n","test_ds = NewsGroupsDataset(test_encod, y_test)\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"3IVU1eJP5Fom","executionInfo":{"status":"ok","timestamp":1622117913536,"user_tz":-120,"elapsed":5,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import mean_squared_error\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  #acc = accuracy_score(labels, preds)\n","  #f1 = f1_score(labels,preds)\n","  mse = mean_squared_error(labels,pred.predictions,squared=False)\n","  return {\n","      #'accuracy': acc,\n","      #'f1_score':f1,\n","      'rmse': mse\n","  }"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPZD0gPb6foq","executionInfo":{"status":"ok","timestamp":1622117913536,"user_tz":-120,"elapsed":4,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=2,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=20,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    # metric_for_best_model = 'f1_score',\n","    metric_for_best_model = 'rmse',\n","    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n","    logging_steps=200,               # log & save weights each logging_steps\n","    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"91rmuLpL5HTg","executionInfo":{"status":"ok","timestamp":1622117914167,"user_tz":-120,"elapsed":634,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["trainer = Trainer(\n","    model=bert_model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_ds,         # training dataset\n","    eval_dataset=dev_ds,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"2DPlcQzZ6yDG","executionInfo":{"status":"ok","timestamp":1622118541082,"user_tz":-120,"elapsed":626918,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"3cf2a441-b707-4550-8731-a9e7acbc455a"},"source":["trainer.train()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='926' max='926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [926/926 10:25, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rmse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.960100</td>\n","      <td>0.403716</td>\n","      <td>0.635386</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.445700</td>\n","      <td>0.458462</td>\n","      <td>0.677099</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.408400</td>\n","      <td>0.396559</td>\n","      <td>0.629730</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.386300</td>\n","      <td>0.398583</td>\n","      <td>0.631334</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=926, training_loss=0.5262977237577829, metrics={'train_runtime': 625.7971, 'train_samples_per_second': 1.48, 'total_flos': 187904449507500.0, 'epoch': 2.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 504422400, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -529268736, 'train_mem_gpu_alloc_delta': 1534215680, 'train_mem_cpu_peaked_delta': 529776640, 'train_mem_gpu_peaked_delta': 1774170624})"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"id":"_8uB3CRnBYKM","executionInfo":{"status":"ok","timestamp":1622118558645,"user_tz":-120,"elapsed":17576,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"e9b4b05f-5795-4282-c589-0534577bd3b4"},"source":["trainer.evaluate(eval_dataset=test_ds)"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [118/118 00:17]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 2.0,\n"," 'eval_loss': 0.4812448024749756,\n"," 'eval_mem_cpu_alloc_delta': 28672,\n"," 'eval_mem_cpu_peaked_delta': 0,\n"," 'eval_mem_gpu_alloc_delta': -21504,\n"," 'eval_mem_gpu_peaked_delta': 146776576,\n"," 'eval_rmse': 0.6937180757522583,\n"," 'eval_runtime': 17.8133,\n"," 'eval_samples_per_second': 131.475}"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"ScI4JFYxB46O","executionInfo":{"status":"ok","timestamp":1622118560404,"user_tz":-120,"elapsed":1778,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["trainer.save_model('best_model_spanBERTA.hdf5')"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWJ91glKrXU9"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"4AA7YsyjrLKD"},"source":["RESULTS CLASSIFICATION\n","\n","```\n","Step\tTraining Loss\tValidation Loss\tAccuracy\tF1 Score\n","200\t0.488500\t0.423187\t0.810000\t0.743820\n","400\t0.410900\t0.389528\t0.823333\t0.727156\n","600\t0.400500\t0.403867\t0.823542\t0.781532\n","800\t0.404100\t0.359039\t0.845833\t0.777644\n","1000\t0.380200\t0.387769\t0.842292\t0.766141\n","1200\t0.349100\t0.350626\t0.853333\t0.795587\n","1400\t0.268600\t0.373516\t0.850417\t0.791158\n","1600\t0.257900\t0.379301\t0.853333\t0.809317\n","1800\t0.248600\t0.382039\t0.849583\t0.813822\n","2000\t0.234700\t0.370870\t0.856458\t0.816707\n","2200\t0.261100\t0.354002\t0.854583\t0.806219\n","2400\t0.228700\t0.362816\t0.858333\t0.817008\n","\n","Test \n","\n","'epoch': 2.0,\n"," 'eval_accuracy': 0.8356666666666667,\n"," 'eval_f1_score': 0.7987755102040816,\n"," 'eval_loss': 0.4098193347454071,\n"," 'eval_mem_cpu_alloc_delta': 16384,\n"," 'eval_mem_cpu_peaked_delta': 0,\n"," 'eval_mem_gpu_alloc_delta': 0,\n"," 'eval_mem_gpu_peaked_delta': 162115584,\n"," 'eval_runtime': 48.4072,\n"," 'eval_samples_per_second': 123.948}\n","\n","```\n","\n","REGRESSION\n","\n","\n","```\n","\n","Test\n","\n","```\n"]}]}