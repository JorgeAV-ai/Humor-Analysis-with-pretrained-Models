{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BETO_PYTORCH_2019.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP++ckfrfuWwLUBE9nZ1DA1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"p2FJz2moGFya","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621892427358,"user_tz":-120,"elapsed":193875,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"d4677a4b-af94-4147-edd6-ddfb098ff50d"},"source":["!pip install transformers\n","!wget https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/pytorch_weights.tar.gz \n","!wget https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/vocab.txt \n","!wget https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/config.json \n","!tar -xzvf pytorch_weights.tar.gz\n","!mv config.json pytorch/.\n","!mv vocab.txt pytorch/."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","--2021-05-24 21:37:16--  https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/pytorch_weights.tar.gz\n","Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n","Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 410039235 (391M) [application/x-gzip]\n","Saving to: ‘pytorch_weights.tar.gz.2’\n","\n","pytorch_weights.tar 100%[===================>] 391.04M   794KB/s    in 2m 56s  \n","\n","2021-05-24 21:40:13 (2.22 MB/s) - ‘pytorch_weights.tar.gz.2’ saved [410039235/410039235]\n","\n","--2021-05-24 21:40:13--  https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/vocab.txt\n","Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n","Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248047 (242K) [text/plain]\n","Saving to: ‘vocab.txt’\n","\n","vocab.txt           100%[===================>] 242.23K   485KB/s    in 0.5s    \n","\n","2021-05-24 21:40:14 (485 KB/s) - ‘vocab.txt’ saved [248047/248047]\n","\n","--2021-05-24 21:40:14--  https://users.dcc.uchile.cl/~jperez/beto/uncased_2M/config.json\n","Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n","Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 313 [application/json]\n","Saving to: ‘config.json’\n","\n","config.json         100%[===================>]     313  --.-KB/s    in 0s      \n","\n","2021-05-24 21:40:15 (64.5 MB/s) - ‘config.json’ saved [313/313]\n","\n","pytorch/\n","pytorch/pytorch_model.bin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sdssjJl5GSzy","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1622134319992,"user_tz":-120,"elapsed":1863,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"ed3181af-af1d-4016-ed9d-9045c72c367e"},"source":["# Libraries\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","# Evaluation\n","import pytorch\n","import torch\n","from torch import nn\n","# import tensorflow_text as text\n","import pandas as pd\n","# from official.nlp import optimization  # to create AdamW optimizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","import np_utils\n","from keras import backend as K\n","# from focal_loss import BinaryFocalLoss\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import activations\n","# import tensorflow_addons as tfa\n","\n","\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-22a7e27d9aa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"jXJI_2iPGZC7","executionInfo":{"status":"ok","timestamp":1622134362766,"user_tz":-120,"elapsed":3662,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}}},"source":["# Read data\n","url = 'https://www.fing.edu.uy/inco/grupos/pln/haha/2019/data/haha_2019_train.csv'\n","url2 = 'https://www.fing.edu.uy/inco/grupos/pln/haha/2019/data/haha_2019_test_gold.csv'\n","train = pd.read_csv(url)\n","testG = pd.read_csv(url2)\n","\n","\n","train = train.loc[train['is_humor'] == 1].copy()\n","testG = testG.loc[testG['is_humor'] == 1].copy()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"45KUJ9EtGZyP","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1622134344204,"user_tz":-120,"elapsed":6,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"1fa4bbc7-6138-4820-dff5-9b7a917ecde8"},"source":["testG"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>is_humor</th>\n","      <th>votes_no</th>\n","      <th>votes_1</th>\n","      <th>votes_2</th>\n","      <th>votes_3</th>\n","      <th>votes_4</th>\n","      <th>votes_5</th>\n","      <th>funniness_average</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1092844370540331008</td>\n","      <td>Historia #36.\\n*Entra corriendo y gritando al ...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1092879430748459009</td>\n","      <td>estoy tomando helado en el centro y pedi tiram...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1092537811419516933</td>\n","      <td>— ¿De 15 o 20 centímetros?\\n\\n— Ven y averígua...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1092866638112792581</td>\n","      <td>Que fea soy</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>332525498250969088</td>\n","      <td>#OMG, VAMOS EN RETROCESO RESULTE CON 40 SEGUID...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5995</th>\n","      <td>1092852595570425856</td>\n","      <td>#ElPulso señor @oscarrenteriaj La corbata ya n...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5996</th>\n","      <td>641393345181425664</td>\n","      <td>¿Hace frío? Acá en el infierno que transformas...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5997</th>\n","      <td>988378375118053376</td>\n","      <td>Buenas días mis cariños y cariñas</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5998</th>\n","      <td>777986884895019009</td>\n","      <td>\"Les digo ven, ven, ven, animalito ven, ven y ...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5999</th>\n","      <td>1046698692663791616</td>\n","      <td>¿Le pusiste a tu hijo Beckham hace 16 años y a...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6000 rows × 10 columns</p>\n","</div>"],"text/plain":["                       id  ... funniness_average\n","0     1092844370540331008  ...               NaN\n","1     1092879430748459009  ...               NaN\n","2     1092537811419516933  ...               1.6\n","3     1092866638112792581  ...               NaN\n","4      332525498250969088  ...               NaN\n","...                   ...  ...               ...\n","5995  1092852595570425856  ...               NaN\n","5996   641393345181425664  ...               NaN\n","5997   988378375118053376  ...               NaN\n","5998   777986884895019009  ...               NaN\n","5999  1046698692663791616  ...               NaN\n","\n","[6000 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"xjKs00W2Gasy","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1622134482353,"user_tz":-120,"elapsed":218,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"99bc73ae-44f5-442e-96a0-90cab40b3101"},"source":["BATCH_SIZE = 32\n","MAX_SEQUENCE_LENGTH = 125\n","bert_tokenizer = BertTokenizer.from_pretrained(\"pytorch/\",do_lower_case=True)\n","bert_model = BertForSequenceClassification.from_pretrained(\"pytorch/\",num_labels=2).to(\"cuda\")\n","\n","# BATCH_SIZE = 32\n","# MAX_SEQUENCE_LENGTH = 125\n","# bert_tokenizer = BertTokenizer.from_pretrained(\"pytorch/\",do_lower_case=True)\n","# bert_model = BertForSequenceClassification.from_pretrained(\"pytorch/\",num_labels=1).to(\"cuda\")"],"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c523cffe1bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbert_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pytorch/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pytorch/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"]}]},{"cell_type":"code","metadata":{"id":"VepTGrG9HNc0"},"source":["x_train, x_dev,y_train, y_dev = train_test_split(train[\"text\"].tolist(),train[\"funniness_average\"].tolist(), test_size=0.2,stratify=train[\"is_humor\"])\n","\n","x_test = testG[\"text\"].tolist()\n","y_test = testG[\"funniness_average\"].tolist()\n","\n","\n","\n","train_encod = bert_tokenizer(x_train,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH) \n","val_encod = bert_tokenizer(x_dev,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH)\n","test_encod = bert_tokenizer(x_test,truncation=True,padding=True,max_length=MAX_SEQUENCE_LENGTH)\n","\n","class NewsGroupsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor([self.labels[idx]])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_ds = NewsGroupsDataset(train_encod, y_train)\n","dev_ds = NewsGroupsDataset(val_encod, y_dev)\n","test_ds = NewsGroupsDataset(test_encod, y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUOFXeqUkAK3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ly--ryiiO7bd"},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import mean_squared_error\n","\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  #acc = accuracy_score(labels, preds)\n","  #f1 = f1_score(labels,preds)\n","  # mse = mean_squared_error(labels,pred.predictions,squared=False)\n","  return {\n","     #  'accuracy': acc,\n","     #  'f1_score':f1,\n","      'rmse': mse\n","  }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqINJIN8PQGI"},"source":["training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=20,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    metric_for_best_model = 'rmse',\n","    logging_steps=200,               # log & save weights each logging_steps\n","    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdNQI7aUrtMz"},"source":["trainer = Trainer(\n","    model=bert_model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_ds,         # training dataset\n","    eval_dataset=dev_ds,          # evaluation dataset\n","    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"2csHlCWEsFUz","executionInfo":{"status":"ok","timestamp":1621893496448,"user_tz":-120,"elapsed":625421,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"c7c5a868-cacf-4f61-928a-ad7ca5052332"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1389' max='1389' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1389/1389 10:24, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rmse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.353900</td>\n","      <td>0.449304</td>\n","      <td>0.670301</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.213200</td>\n","      <td>0.479600</td>\n","      <td>0.692531</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.361600</td>\n","      <td>0.480087</td>\n","      <td>0.692883</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.346600</td>\n","      <td>0.429327</td>\n","      <td>0.655230</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.275200</td>\n","      <td>0.472948</td>\n","      <td>0.687712</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.167700</td>\n","      <td>0.457578</td>\n","      <td>0.676445</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1389, training_loss=0.26800040841703365, metrics={'train_runtime': 625.055, 'train_samples_per_second': 2.222, 'total_flos': 200908559669292.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -488660992, 'train_mem_gpu_alloc_delta': 880645120, 'train_mem_cpu_peaked_delta': 488669184, 'train_mem_gpu_peaked_delta': 1349762048})"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"uqtgKvWS9zJ3","colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"status":"ok","timestamp":1621893507501,"user_tz":-120,"elapsed":10342,"user":{"displayName":"Jorge Alcañiz","photoUrl":"","userId":"04906363900172730711"}},"outputId":"19c6cadd-ad6d-47c1-9619-75ae560940f6"},"source":["trainer.evaluate(eval_dataset=test_ds)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [118/118 00:09]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_loss': 0.48496299982070923,\n"," 'eval_mem_cpu_alloc_delta': 0,\n"," 'eval_mem_cpu_peaked_delta': 0,\n"," 'eval_mem_gpu_alloc_delta': 0,\n"," 'eval_mem_gpu_peaked_delta': 71310848,\n"," 'eval_rmse': 0.6963928937911987,\n"," 'eval_runtime': 10.1092,\n"," 'eval_samples_per_second': 231.67}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"JTOvNNDU3cAK"},"source":["trainer.save_model('best_model_BETO_rmse.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7htZDiMvcKB"},"source":["Results:\n","\n","    Step\tTraining Loss\tValidation Loss\tAccuracy\tF1 Score\n","    200\t0.513800\t0.443248\t0.782083\t0.758764\n","    400\t0.392800\t0.337235\t0.857083\t0.803326\n","    600\t0.376500\t0.339753\t0.847708\t0.784047\n","    800\t0.374800\t0.345030\t0.859167\t0.801293\n","    1000\t0.381600\t0.327242\t0.861042\t0.824704\n","    1200\t0.358000\t0.347017\t0.859375\t0.822322\n","    1400\t0.264400\t0.393742\t0.842292\t0.813409\n","    1600\t0.249500\t0.360212\t0.871875\t0.830438\n","    1800\t0.239200\t0.387446\t0.863958\t0.828564\n","    2000\t0.247400\t0.336539\t0.870417\t0.832345\n","    2200\t0.229900\t0.384619\t0.866250\t0.831230\n","    2400\t0.238700\t0.345918\t0.867083\t0.831038\n","\n","\n","\n","Results test:\n","\n","    {'epoch': 2.0,\n","    'eval_accuracy': 0.8473333333333334,\n","    'eval_f1_score': 0.8133659331703341,\n","    'eval_loss': 0.3893824815750122,\n","    'eval_mem_cpu_alloc_delta': 0,\n","    'eval_mem_cpu_peaked_delta': 0,\n","    'eval_mem_gpu_alloc_delta': 0,\n","    'eval_mem_gpu_peaked_delta': 135538176,\n","    'eval_runtime': 42.7059,\n","    'eval_samples_per_second': 140.496}\n","\n","\n","\n","\n","\n","Results train:\n","\n","    Step\tTraining Loss\tValidation Loss\tRmse\n","    200\t0.353900\t0.449304\t0.670301\n","    400\t0.213200\t0.479600\t0.692531\n","    600\t0.361600\t0.480087\t0.692883\n","    800\t0.346600\t0.429327\t0.655230\n","    1000\t0.275200\t0.472948\t0.687712\n","    1200\t0.167700\t0.457578\t0.676445\n","\n","Results test:\n","\n","    {'epoch': 3.0,\n","    'eval_loss': 0.48496299982070923,\n","    'eval_mem_cpu_alloc_delta': 0,\n","    'eval_mem_cpu_peaked_delta': 0,\n","    'eval_mem_gpu_alloc_delta': 0,\n","    'eval_mem_gpu_peaked_delta': 71310848,\n","    'eval_rmse': 0.6963928937911987,\n","    'eval_runtime': 10.1092,\n","    'eval_samples_per_second': 231.67}\n"]},{"cell_type":"markdown","metadata":{"id":"0TOG-NBjPseH"},"source":["https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python "]}]}